{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "This Jupyter notebook includes all code for creating feature matrices and running a machine learning classifier. Some cells in this Jupyter notebook are nonfunctional, since some data files are too large for this github repository. Please adjust file paths as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GroupKFold, GroupShuffleSplit, ShuffleSplit\n",
    "from sklearn.metrics import f1_score, make_scorer, roc_curve\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "import csv\n",
    "import preprocessing_utils\n",
    "from preprocessing_utils import getPhenotypeData, getFeatureIntersectionDataSparse_PSP\n",
    "from sklearn import feature_selection\n",
    "import scipy\n",
    "import pickle\n",
    "from collections import Counter\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "featType1 = 'PSP_SimpleRepeats'\n",
    "featType2 = 'SimpleRepeats'\n",
    "X, index = getFeatureIntersectionDataSparse_PSP(featType1, featType2)\n",
    "y = getPhenotypeData(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number Control: \", y.shape[0]-np.count_nonzero(y))\n",
    "print(\"Number Cases: \", np.count_nonzero(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Classifier\n",
    "The following segment of code splits the data into train and test sets. A logistic regression classifier is trained on the training set and evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_ind.pkl', 'rb') as f: #load from pre-saved training data\n",
    "    train_ind = pickle.load(f)\n",
    "with open('test_ind.pkl', 'rb') as f: #load from pre-saved training data\n",
    "    test_ind = pickle.load(f)\n",
    "\n",
    "X_train = X.getSampleSet(train_ind)\n",
    "y_train = y[train_ind]\n",
    "X_test = X.getSampleSet(test_ind)\n",
    "y_test = y[test_ind]\n",
    "\n",
    "print 'Size of Train X Matrix:', X_train.getMat().shape\n",
    "print 'Size of Train y:', len(y_train)\n",
    "print 'Size of Test X Matrix:', X_test.getMat().shape\n",
    "print 'Size of Test y:', len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Classifier - Guessing 0 for all or Guessing 1 for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total0 = 0\n",
    "total1 = 0\n",
    "for j in range(10):\n",
    "    y_test = np.array(y_test)\n",
    "    correct0 = 0\n",
    "    correct1 = 0\n",
    "    total = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if(y_test[i]==0): correct0 += 1\n",
    "        elif(y_test[i]==1): correct1 += 1\n",
    "        total += 1.0\n",
    "    total0 += (correct0/total)\n",
    "    total1 += (correct1/total)\n",
    "print 'Naive Approach - Guessing 0 for All: ', total0/10\n",
    "print 'Naive Approach - Guessing 1 for All: ', total1/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier - 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "allPosVariants = []\n",
    "allNegVariants = []\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "trainsamples = list(X_train.getSamples())\n",
    "train_famids = [str(x) for x in range(len(trainsamples))]\n",
    "\n",
    "with open('data/v34.vcf.csv', 'rU') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        sample = row[0].split(',')\n",
    "        if(sample[1] in trainsamples):\n",
    "            train_famids[trainsamples.index(sample[1])] = sample[0]\n",
    "\n",
    "#Evaluate across all five folds\n",
    "k = 1\n",
    "for train_kindex, val_index in group_kfold.split(X_train.getMat(), y_train, train_famids):\n",
    "    X_ktrain = X_train.getSampleSet(train_kindex)\n",
    "    y_ktrain = y_train[train_kindex]\n",
    "    X_val = X_train.getSampleSet(val_index)\n",
    "    y_val = y_train[val_index]   \n",
    "    logreg = linear_model.LogisticRegression(penalty='l1', C=0.1, class_weight='balanced') #adjust for class imbalance\n",
    "    print '\\n5-Fold Cross Validation: Fold %d' % k\n",
    "    logreg.fit(X_ktrain.getMat(), y_ktrain)\n",
    "    print 'Train Accuracy:', logreg.score(X_ktrain.getMat(), y_ktrain)\n",
    "    print 'Test Accuracy: ', logreg.score(X_val.getMat(), y_val)\n",
    "    \n",
    "    y_pred = logreg.predict(X_val.getMat())\n",
    "    print 'Cohen Kappa Statistic: ', cohen_kappa_score(y_val, y_pred) #good metric for imbalanced classes\n",
    "    print 'F1_Score: ', f1_score(y_val, y_pred)\n",
    "    print 'Recall: ', skm.recall_score(y_val, y_pred)\n",
    "    print 'Precision: ', skm.precision_score(y_val, y_pred)\n",
    "    cnf_matrix = skm.confusion_matrix(y_val, y_pred)\n",
    "    print 'Confusion Matrix: \\n', cnf_matrix\n",
    "\n",
    "    probas_ = logreg.fit(X_ktrain.getMat(), y_ktrain).decision_function(X_val.getMat())\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, probas_)\n",
    "    plt.plot(fpr, tpr, color = 'darkorange', label = 'ROC curve')\n",
    "    plt.plot([0,1], [0,1], color = 'navy', linestyle = '--')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot()\n",
    "    precision, recall, _ = precision_recall_curve(abs(y_val-1), 1-probas_)\n",
    "    plt.step(recall, precision, color='b', alpha=1, where='post')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    average_precision = average_precision_score(y_val, probas_)\n",
    "    plt.title('2-class Precision-Recall curve with Flipped Class Labels: Avg P={0:0.2f}'.format(average_precision))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    negargs = list((logreg.coef_).argsort()[0, 0:5])\n",
    "    posargs = list((logreg.coef_).argsort()[0, -5:])\n",
    "    print 'Test AUC-ROC:', roc_auc_score(y_val, probas_)  \n",
    "\n",
    "    topvalnegvariants = []\n",
    "    topvalposvariants = []\n",
    "\n",
    "    for elem in negargs:\n",
    "        topvalnegvariants.append(X_ktrain.getFeatures()[elem])\n",
    "        print logreg.coef_[0,elem], \n",
    "    for elem in posargs:\n",
    "        topvalposvariants.append(X_ktrain.getFeatures()[elem])\n",
    "        print logreg.coef_[0,elem], \n",
    "\n",
    "    print '\\nTop Positive Variants: ',\n",
    "    for elem in topvalposvariants:\n",
    "        allPosVariants.append(elem)\n",
    "        print elem,\n",
    "    print '\\nTop Negative Variants: ',\n",
    "    for elem in topvalnegvariants:\n",
    "        allNegVariants.append(elem)\n",
    "        print elem,\n",
    "    print ''\n",
    "\n",
    "    k+=1\n",
    "\n",
    "print '\\nTop Positive variants that occur in exactly two folds: ', \n",
    "cnt = Counter(allPosVariants)\n",
    "for elem in [k for k, v in cnt.iteritems() if v == 2]: print elem,\n",
    "print '\\nTop Positive variants that occur in exactly three folds: ', \n",
    "for elem in [k for k, v in cnt.iteritems() if v == 3]: print elem,\n",
    "print '\\nTop Positive variants that occur in exactly four folds: ', \n",
    "for elem in [k for k, v in cnt.iteritems() if v == 4]: print elem,\n",
    "print '\\nTop Positive variants that occur in exactly five folds: ', \n",
    "for elem in [k for k, v in cnt.iteritems() if v == 5]: print elem,\n",
    "\n",
    "print '\\nTop Negative variants that occur in exactly two folds: ', \n",
    "cnt = Counter(allNegVariants)\n",
    "for elem in [k for k, v in cnt.iteritems() if v == 2]: print elem,\n",
    "print '\\nTop Negative variants that occur in exactly three folds: ', \n",
    "for elem in [k for k, v in cnt.iteritems() if v == 3]: print elem,\n",
    "print '\\nTop Negative variants that occur in exactly four folds: ', \n",
    "for elem in [k for k, v in cnt.iteritems() if v == 4]: print elem,\n",
    "print '\\nTop Negative variants that occur in exactly five folds: ', \n",
    "for elem in [k for k, v in cnt.iteritems() if v == 5]: print elem,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier - Entire training set and held-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(penalty='l1', C=0.1, class_weight='balanced') #adjust for class imbalance\n",
    "print 'Training across entire set and using test set'\n",
    "logreg.fit(X_train.getMat(), y_train)\n",
    "\n",
    "print 'Train Accuracy: {0:0.3f}'.format(logreg.score(X_train.getMat(), y_train))\n",
    "print 'Test Accuracy: {0:0.3f}'.format(logreg.score(X_test.getMat(), y_test))\n",
    "\n",
    "y_pred = logreg.predict(X_test.getMat())\n",
    "print 'Cohen Kappa Statistic: {0:0.3f}'.format(cohen_kappa_score(y_test, y_pred)) #good metric for imbalanced classes\n",
    "print 'F1_Score: {0:0.3f}'.format(f1_score(y_test, y_pred))\n",
    "print 'Recall: {0:0.3f}'.format(skm.recall_score(y_test, y_pred))\n",
    "print 'Precision: {0:0.3f}'.format(skm.precision_score(y_test, y_pred))\n",
    "cnf_matrix = skm.confusion_matrix(y_test, y_pred)\n",
    "print 'Confusion Matrix: \\n', cnf_matrix\n",
    "\n",
    "probas_ = logreg.fit(X_train.getMat(), y_train).decision_function(X_test.getMat())\n",
    "# Compute ROC curve and area the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_)\n",
    "plt.plot(fpr, tpr, color = 'darkorange', label = 'ROC curve')\n",
    "plt.plot([0,1], [0,1], color = 'navy', linestyle = '--')\n",
    "plt.show()\n",
    "\n",
    "plt.plot()\n",
    "precision, recall, _ = precision_recall_curve(abs(y_test-1), 1-probas_)\n",
    "plt.step(recall, precision, color='b', alpha=1, where='post')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "average_precision = average_precision_score(y_test, probas_)\n",
    "plt.title('2-class Precision-Recall curve with Flipped Class Labels: Avg P={0:0.2f}'.format(average_precision))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "args = list((logreg.coef_).argsort()[0, 0:5])\n",
    "args.extend((logreg.coef_).argsort()[0, -5:])\n",
    "print np.count_nonzero(logreg.coef_)\n",
    "print 'Test AUC-ROC: {0:0.3f}'.format(roc_auc_score(y_test, probas_))\n",
    "\n",
    "topvariants = []\n",
    "for elem in args:\n",
    "    topvariants.append(X_train.getFeatures()[elem])\n",
    "    print logreg.coef_[0,elem], \n",
    "\n",
    "print ''    \n",
    "for elem in topvariants:\n",
    "    print elem, \n",
    "print ''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
